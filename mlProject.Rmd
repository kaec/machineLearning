---
title: "Machine Learning"
author: "kaec"
date: "Saturday, November 22, 2014"
output: html_document
---
## Data Loading
The data used in this machine learning investigation comes from http://groupware.les.inf.puc-rio.br/har . It is a collection of reading's from accelerometers on the belt, forearm, arm, and dumbell. The measurements where taken from 6 participants who performed 10 repititions of dumbell lifts in the correct way and in 4 different wrong ways.
For convenience the data has already been split into training and test data. Firstly, the training and test data is loaded.

```{r, gettingData, cache= TRUE}
testDstFile <- "test.csv"
trainDstFile <- "train.csv"

download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", testDstFile)
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", trainDstFile)

testData <- read.csv(testDstFile)
trainData <- read.csv(trainDstFile)

names(testData)
str(testData)
```

According to the available data documentation, the "classe" variable describes how the dumbell exercise was done. "A" denotes the correctly done exercise, "B" to "E" describe the exercise done in some way incorrectly. 

This investigation will try to predict a discrete value output (A - E) which means dealing with a Classification problem.

## Prediction Model
First of all the seed is set so that the research is reproducible. 

The first 7 columns of the data contain entries related to the participant and time, which are less useful for the predicition, if the prediction should just be done based on the measurments of the accelerometers. 
Also data contains some factor variables (excluding classe) which have empty data, wrong entries (Div0), or unchanging values. Therefore these columns are removed from the training data. 

To be able to test the prediction model, the training data is split again into the actual training data for the model and cross validation data. 

```{r, subsetData}
library(caret)

set.seed(1234)

train <- trainData[ , -c(1:7)]

trainNA <- train[ , colSums(is.na(train)) == 0 ]
notFac <- sapply(trainNA, is.factor)
trainFac <- trainNA[, c(names(trainNA)[!notFac], "classe")]

cv <- createDataPartition( y = trainFac$classe, p = 0.75, list= FALSE)
cvSet<- trainFac[-cv, ]
trainSet <- trainFac[cv,]
```

As there is no performance target and the goal is to do multivariable classification, I will use random forests as a prediction model to get good accuracy. 

```{r train, cache= TRUE}
fit <- train( classe ~ . , data = train, method = "rf")

fit
```

The Confusion matrix looks like this:

Confusion matrix:
     A    B    C    D    E  class.error
A 4181    3    0    0    1 0.0009557945
B   16 2827    4    1    0 0.0073735955
C    0   14 2542   11    0 0.0097389949
D    0    0   28 2381    3 0.0128524046
E    0    0    4    5 2697 0.0033259424

With an accuracy of 0.989. 

To ensure that the fitted model is not overfitting and predicting correctly, the cross validation dataset is used. Based on the given mesurements, the model is used to predict the classe. Finally, the predicted classes are compared with the actual classe. 
```{r predict}
result <- predict( fit, newdata = cvSet)

confusionMatrix(result, cvSet$classe)
```

The out of sample error is expected to be higher than in the in sample error. 

In the case of the cross validation dataset the confusion matrix looks as follows:


Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1394    5    0    0    0
         B    1  936    5    0    0
         C    0    7  847    9    0
         D    0    0    3  795    0
         E    0    1    0    0  901

Overall Statistics
                                         
               Accuracy : 0.9937         
                 95% CI : (0.991, 0.9957)
    No Information Rate : 0.2845         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.992          
 Mcnemar's Test P-Value : NA  

Interestingly enough, the reported accuracy here is higher than the that of the traing data and therefore the error must be smaller. 

